{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Tabular POMDP\n",
    "\n",
    "In this tutorial we will define a version of the Tiger POMDP example [1] with a tabular representation. \n",
    "\n",
    "To find out more about the explicit interface, please see this section of the POMDPs.jl documentation: [Explicit POMDP Interface](http://juliapomdp.github.io/POMDPs.jl/latest/explicit.html).\n",
    "\n",
    "For a more detailed problem description and an alternative way of implementing it using a functional form see [Defining-a-POMDP-with-the-Explicit-Interface](https://github.com/JuliaPOMDP/POMDPExamples.jl/blob/master/notebooks/Defining-a-POMDP-with-the-Explicit-Interface.ipynb).\n",
    "\n",
    "[1] L. Pack Kaelbling, M. L. Littman, A. R. Cassandra, \"Planning and Action in Partially Observable Domain\", Artificial Intelligence, 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using POMDPs\n",
    "using POMDPModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `TabularPOMDP` model provided by the package [POMDPModels.jl](https://github.com/JuliaPOMDP/POMDPModels.jl). \n",
    "The states, actions and observations are represented by integers.\n",
    "\n",
    "The Tiger POMDP consists of 2 states, 3 actions, and 2 observations. The correspondence with the problem definition is as follows:\n",
    "\n",
    "|integer | state\n",
    "|--------|--------\n",
    "|1       | tiger on the left \n",
    "|2       | tiger on the right \n",
    "\n",
    "|integer | observation\n",
    "|--------|--------\n",
    "|1       | hear on the left \n",
    "|2       | hear on the right \n",
    "   \n",
    "|integer | action\n",
    "|--------|--------\n",
    "|1       | open left \n",
    "|2       | open right\n",
    "|3       | listen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Matrix\n",
    "\n",
    "The transition matrix is of size $2\\times3\\times2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 0.0  0.5  0.5\n",
       " 1.0  0.5  0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = zeros(2,3,2) # |S|x|A|x|S|, T[s', a, s] = p(s'|a,s)\n",
    "T[:,:,1] = [1. 0.5 0.5; \n",
    "            0. 0.5 0.5]\n",
    "T[:,:,2] = [0. 0.5 0.5; \n",
    "            1. 0.5 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Matrix\n",
    "\n",
    "The observation matrix is of size $2\\times3\\times2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 0.15  0.5  0.5\n",
       " 0.85  0.5  0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = zeros(2,3,2) # |O|x|A|x|S|, O[o, a, s] = p(o|a,s)\n",
    "O[:,:,1] = [0.85 0.5 0.5; \n",
    "            0.15 0.5 0.5]\n",
    "O[:,:,2] = [0.15 0.5 0.5; \n",
    "            0.85 0.5 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Matrix\n",
    "\n",
    "The reward matrix is of size $2 \\times 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " -1.0  -100.0    10.0\n",
       " -1.0    10.0  -100.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = [-1. -100. 10.; \n",
    "     -1. 10. -100.] # |S|x|A| state-action pair rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model \n",
    "\n",
    "We can now instantiate a `TabularPOMDP` object. \n",
    "\n",
    "In addition to the transition, observation, and reward matrices we also need to give a discount factor in the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.95\n",
    "\n",
    "pomdp = TabularPOMDP(T, R, O, discount);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeing the model in action\n",
    "\n",
    "When using the `TabularPOMDP` representation, all the functions from the explicit interface are automatically implemented and the model is ready to be used for simulation or solving. \n",
    "\n",
    "To learn how to solve POMDPs offline: TODO[link to tutorial]\n",
    "\n",
    "To learn how to solve POMDPs online: TODO[link_to_tutorial]\n",
    "\n",
    "We can run a simulation of our model using the `stepthrough` function\n",
    "\n",
    "For more information on running simulations, see the [simulation tutorial](https://github.com/JuliaPOMDP/POMDPExamples.jl/blob/master/notebooks/Running-Simulations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s = 2\n",
      "a = 2\n",
      "r = 10.0\n",
      "\n",
      "s = 1\n",
      "a = 3\n",
      "r = 10.0\n",
      "\n",
      "s = 2\n",
      "a = 2\n",
      "r = 10.0\n",
      "\n",
      "s = 1\n",
      "a = 1\n",
      "r = -1.0\n",
      "\n",
      "s = 1\n",
      "a = 3\n",
      "r = 10.0\n",
      "\n",
      "s = 2\n",
      "a = 3\n",
      "r = -100.0\n",
      "\n",
      "s = 1\n",
      "a = 1\n",
      "r = -1.0\n",
      "\n",
      "s = 1\n",
      "a = 1\n",
      "r = -1.0\n",
      "\n",
      "s = 1\n",
      "a = 1\n",
      "r = -1.0\n",
      "\n",
      "s = 1\n",
      "a = 1\n",
      "r = -1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using POMDPSimulators\n",
    "using POMDPPolicies\n",
    "\n",
    "# policy that takes a random action\n",
    "policy = RandomPolicy(pomdp)\n",
    "\n",
    "for (s, a, r) in stepthrough(pomdp,policy, \"s,a,r\", max_steps=10)\n",
    "    @show s\n",
    "    @show a\n",
    "    @show r\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
